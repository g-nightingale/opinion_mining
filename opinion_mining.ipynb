{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cc7061",
   "metadata": {},
   "source": [
    "# CM500328 Introduction to NLP: Final Assignment\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The aim of this assignment is to carry out opinion mining on reviews of a range of products.  \n",
    "\n",
    "Specifically, given a set of reviews, the task is to identify keyphrases that describe product features and detect the polarity of sentences that discuss these product features. Product features and associated sentiments are identified at the sentence level. These results are aggregated to summarise product features and the senitments associated with them. The data used has been extracted from Amazon and have been manually annotated with product features and opinion polarity. \n",
    "\n",
    "In this assignment we trial two different methodologies:  \n",
    "1. Development of an algorithm to identify features and sentence polarity, similar to the work of Hu and Liu (2004) \n",
    "2. A Machine Learning (ML) method to predict sentence level sentiment using tf-idf vectors and a Support Vector Classifier (SVC)\n",
    "    \n",
    "The remainder of this assignment is structured as follows:\n",
    "\n",
    "1. **Analyse the data and the task**\n",
    "    - In this section we read in the data, take care of preliminary cleansing activities and transform the data into useable data structures\n",
    "\n",
    "\n",
    "2. **Apply relevant data pre-processing steps**\n",
    "    - In this section we carry out data pre-processing steps and creation of training and test sets\n",
    "\n",
    "\n",
    "3. **Extract relevant information**\n",
    "    - We identify relevant product features and the sentiment pertaining to these features\n",
    "\n",
    "\n",
    "4. **Apply a relevant algorithm**\n",
    "    - We produce summary reviews at the feature level for a given product\n",
    "\n",
    "\n",
    "5. **Report evaluation results**\n",
    "    - We report the evaluation results of the approaches using precision and recall metrics\n",
    "    - We produce an NLP pipeline so that we can easily apply our algorithm to multiple products\n",
    "\n",
    "\n",
    "6. **Machine Learning method**  \n",
    "    - We implement a supervised learning approach using tf-idf word vectors and a Support Vector Classifier (SVC) to predict sentence polarity\n",
    "    - Results are compared with our original method  \n",
    "  \n",
    " \n",
    "7. **Conclusions**\n",
    "    - A summary of the key findings  \n",
    "  \n",
    "  \n",
    "8. **References**\n",
    "    - A list of references used in this assignment\n",
    "    \n",
    "Throughout this assignment, the code used for each section is presented at the start of the section so that reviewers can easily refer to the code used for a given section.\n",
    "\n",
    "\n",
    "### Notes\n",
    "**Packages:** The packages and versions used are detailed in the requirements.txt file, found in the same directory as this notebook  \n",
    "**Data:** It is assumed that the \"Data\" folder containing subfolders is stored in the same directory as this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9548f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, codecs\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk, RegexpParser, Tree\n",
    "from copy import deepcopy\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d2b33",
   "metadata": {},
   "source": [
    "### 1. Analyse the data and the task\n",
    "\n",
    "In this step we will read in the data for the reviews and perform some intial data cleansing. Specifically, we ignore several tags specified by Hu and Liu (2004), including titles denoted by [t] and other tags such as [u], [p], [s], [cc] and [cs]. These tags are note deemed to be useful for this assignment.   \n",
    "\n",
    "After processing the data is separated into the following data structures:\n",
    "\n",
    "| Name | Type | Description |\n",
    "|:-----|:-----|:------------|\n",
    "| labels | dict | Groundtruth labels for each sentence |\n",
    "| reviews | dict | Review sentences, each sentence in a review is a separate record. Reviews can span multiple sentences. |\n",
    "| other | dict | Data not classified as tags or text |\n",
    "| data | str | The entire input string afer initial cleansing |\n",
    "\n",
    "For the sake of example and explanation, we will work through the detailed steps of the pipeline for a single product. In section 5, we will put all these steps together to create a unified pipeline and compare performance across multiple products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ee2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in(folders=None, single_file=None, exclude=[\"Readme.txt\"], verbose=False):\n",
    "    \"\"\" \n",
    "    Read in data and store as a string\n",
    "    \"\"\"\n",
    "    file_string = \"\"\n",
    "    \n",
    "    if folders is not None:\n",
    "        for folder in folders:\n",
    "            for a_file in os.listdir(folder):\n",
    "                if not a_file.startswith(\".\") and a_file not in exclude:\n",
    "                    if verbose:\n",
    "                        print(f\"Reading data from: {folder + a_file}\")\n",
    "                    with codecs.open(folder + a_file, 'r', encoding='iso-8859-1', errors=\"ignore\") as f:\n",
    "                        file_string += f.read()\n",
    "    elif single_file is not None:\n",
    "        if verbose:\n",
    "            print(f\"Reading data from: {single_file}\")\n",
    "        with codecs.open(single_file, 'r', encoding='iso-8859-1', errors=\"ignore\") as f:\n",
    "            file_string += f.read()\n",
    "    else:\n",
    "        raise ValueError(\"Please provide a list of folders or a path to a single file\")\n",
    "    \n",
    "    return file_string\n",
    "\n",
    "\n",
    "def create_dicts(data):\n",
    "    \"\"\" \n",
    "    Converts the raw string into three dictionaries:\n",
    "        1. labels: labels for each line\n",
    "        2. text: The lines for each review\n",
    "        3. other: text that cannot be identified as labels or text\n",
    "        \n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    reviews = {}\n",
    "    other = {}\n",
    "    count = 0\n",
    "    other_count = 0\n",
    "    \n",
    "    data = data.replace(\"]#\", \"] #\")\n",
    "    data = data.replace(\"[p]\", \"\")\n",
    "    data = data.replace(\"[u]\", \"\")\n",
    "    data = data.replace(\"[s]\", \"\")\n",
    "    data = data.replace(\"[cc]\", \"\")\n",
    "    data = data.replace(\"[cs]\", \"\")\n",
    "    \n",
    "    for line in data.split(\"\\r\\n\"):\n",
    "        line = line.strip()\n",
    "        if len(re.findall('^[\\w#]+', line)) == 0:\n",
    "            other[other_count] = line\n",
    "            other_count += 1\n",
    "        else:\n",
    "            text_split = line.split(\"##\")\n",
    "            labels[count] = text_split[0]\n",
    "            if len(text_split) > 1:\n",
    "                reviews[count] = text_split[1]\n",
    "            count += 1\n",
    "            \n",
    "    return labels, reviews, other, data\n",
    "\n",
    "def sort_dict(dic, reverse=True):\n",
    "    \"\"\" \n",
    "    Helper function that sorts a dictionary by values \n",
    "    \"\"\"\n",
    "    dic = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse=reverse)}\n",
    "    return dic\n",
    "\n",
    "def print_dict(dic, n=10):\n",
    "    \"\"\" \n",
    "    Helper function that prints the first n items from a dictionary \n",
    "    \"\"\"\n",
    "    c = 0\n",
    "    for k, v in dic.items():\n",
    "        if c > n:\n",
    "            break\n",
    "        print(f'{k}: {v}')\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b8020",
   "metadata": {},
   "source": [
    "Let's start with a single product, the Canon G3. As mentioned beforehand, we will apply the entire pipeline to a wider range of products in section 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad5a78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: data/Customer_review_data/Canon G3.txt\n"
     ]
    }
   ],
   "source": [
    "product = 'Canon G3'\n",
    "file = 'data/Customer_review_data/Canon G3.txt'\n",
    "\n",
    "# Read data and check length\n",
    "data = read_in(single_file=file, verbose=True)\n",
    "labels, reviews, other, data_clean = create_dicts(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c230d3a",
   "metadata": {},
   "source": [
    "Let's observe the labels from the first 10 records of the labels, reviews and other dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb3bf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: canon powershot g3[+3] \n",
      "1: use[+2] \n",
      "2: \n",
      "3: \n",
      "4: picture[+2] \n",
      "5: picture quality[+1] \n",
      "6: picture quality[+1] \n",
      "7: \n",
      "8: camera[+2], use[+2], feature[+1] \n",
      "9: picture quality[+3], use[+1], option[+1] \n",
      "10: \n"
     ]
    }
   ],
   "source": [
    "print_dict(labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a26d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: i recently purchased the canon powershot g3 and am extremely satisfied with the purchase .\n",
      "1: the camera is very easy to use , in fact on a recent trip this past week i was asked to take a picture of a vacationing elderly group .\n",
      "2: after i took their picture with their camera , they offered to take a picture of us .\n",
      "3: i just told them , press halfway , wait for the box to turn green and press the rest of the way .\n",
      "4: they fired away and the picture turned out quite nicely . ( as all of my pictures have thusfar ) .\n",
      "5: a few of my work constituants owned the g2 and highly recommended the canon for picture quality .\n",
      "6: i 'm easily enlarging pictures to 8 1/2 x 11 with no visable loss in picture quality and not even using the best possible setting as yet ( super fine ) .\n",
      "7: ensure you get a larger flash , 128 or 256 , some are selling with the larger flash , 32mb will do in a pinch but you 'll quickly want a larger flash card as with any of the 4mp cameras .\n",
      "8: bottom line , well made camera , easy to use , very flexible and powerful features to include the ability to use external flash and lense / filters choices .\n",
      "9: i 'd highly recommend this camera for anyone who is looking for excellent quality pictures and a combination of ease of use and the flexibility to get advanced with many options to adjust if you like .\n",
      "10: great job canon !\n"
     ]
    }
   ],
   "source": [
    "print_dict(reviews, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "103cc26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: *****************************************************************************\n",
      "1: * Annotated by: Minqing Hu and Bing Liu, 2004.\n",
      "2: *\t\tDepartment of Computer Sicence\n",
      "3: *               University of Illinios at Chicago\n",
      "4: *\n",
      "5: * Product name: Canon G3\n",
      "6: * Review Source: amazon.com\n",
      "7: *\n",
      "8: * See Readme.txt to find the meaning of each symbol.\n",
      "9: *****************************************************************************\n",
      "10: \n"
     ]
    }
   ],
   "source": [
    "print_dict(other, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b2c2f",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we have:\n",
    "    <li> Read in the data </li>\n",
    "    <li> Extracted reviews and labels from the raw data </li>   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d38830",
   "metadata": {},
   "source": [
    "### 2. Apply relevant data pre-processing steps\n",
    "\n",
    "In this section we will apply relevant preprocessing steps to the sentences stored in the text dictionary.\n",
    "\n",
    "**Specifically we will:**\n",
    "1. Convert sentences to lemma form and lower case\n",
    "2. Remove tokens less than the minimum specified token length, we will use a minimum length of 3\n",
    "\n",
    "I have leveraged the spaCy token.lemma_ functionality to reduce words to their base lemma, which will prove useful in reducing dimensionality when trying to identify product features and opinion words.\n",
    "\n",
    "I have experimented with stopword removal, which appears to degrade the overall performance of the algorithm, so stopwords have been retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48afa348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, remove_stopwords=False, min_token_length=3):\n",
    "    \"\"\" \n",
    "    Apply text preprocessing steps \n",
    "    \"\"\"\n",
    "    doc = nlp(text, disable=[\"ner\"])\n",
    "    if remove_stopwords:\n",
    "        return \" \".join([token.lemma_.lower() for token in doc if not token.is_stop \n",
    "                         and len(token.text) >= min_token_length])\n",
    "    else:\n",
    "        return \" \".join([token.lemma_.lower() for token in doc if len(token.text) >= min_token_length])\n",
    "\n",
    "def clean_text(text_dict, remove_stopwords, verbose=False, min_token_length=3):\n",
    "    \"\"\" \n",
    "    Apply test processing to clean the text\n",
    "    \"\"\"\n",
    "    text_clean = {}\n",
    "    count = 0\n",
    "    for k, v in text_dict.items():\n",
    "        if verbose and count%100==0 and count>0:\n",
    "            print(f\"Records processed: {count}\")\n",
    "        text_clean[k] = process_text(v, remove_stopwords, min_token_length)\n",
    "        count += 1\n",
    "        \n",
    "    return text_clean\n",
    "\n",
    "def create_train_test_indicies(text_dict, test_percent, random_seed=42):\n",
    "    \"\"\" \n",
    "    Generate train and test set indicies \n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    train_n = int(len(text_dict) * (1 - test_percent))\n",
    "    idx_list = list(text_dict.keys())\n",
    "    np.random.shuffle(idx_list)\n",
    "    \n",
    "    train_indicies = idx_list[:train_n]\n",
    "    test_indicies = idx_list[train_n:]\n",
    "                      \n",
    "    return train_indicies, test_indicies\n",
    "    \n",
    "def create_train_test_sets(x, y, test_percent, random_seed=42, verbose=False):\n",
    "    \"\"\"\n",
    "    Returns train and test sets given indicies for train and test\n",
    "    \"\"\"\n",
    "    # First get the indidices for splitting\n",
    "    train_indicies, test_indicies= create_train_test_indicies(x, test_percent, random_seed=random_seed)\n",
    "    \n",
    "    # Initialise dictionaries to store output data\n",
    "    x_train = {}\n",
    "    y_train = {}\n",
    "    x_test = {}\n",
    "    y_test = {}\n",
    "    \n",
    "    # Build datsets\n",
    "    for i in train_indicies:\n",
    "        x_train[i] = x[i]\n",
    "        y_train[i] = y[i]\n",
    "        \n",
    "    for i in test_indicies:\n",
    "        x_test[i] = x[i]\n",
    "        y_test[i] = y[i]    \n",
    "        \n",
    "    if verbose:\n",
    "        print(f'x_train records: {len(x_train)}')\n",
    "        print(f'y_train records: {len(y_train)}')\n",
    "        print(f'x_test records: {len(x_test)}')\n",
    "        print(f'y_test records: {len(y_test)} \\n')\n",
    "          \n",
    "    return x_train, y_train, x_test, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9615f45b",
   "metadata": {},
   "source": [
    "Let's apply the preprocessing on the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c8a0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: i recently purchase the canon powershot g3 and be extremely satisfied with the purchase .\n",
      "1: the camera be very easy to use , in fact on a recent trip this past week i be ask to take a picture of a vacation elderly group .\n",
      "2: after i take their picture with their camera , they offer to take a picture of we .\n",
      "3: i just tell they , press halfway , wait for the box to turn green and press the rest of the way .\n",
      "4: they fire away and the picture turn out quite nicely . ( as all of my picture have thusfar ) .\n",
      "5: a few of my work constituant own the g2 and highly recommend the canon for picture quality .\n",
      "6: i ' m easily enlarge picture to 8 1/2 x 11 with no visable loss in picture quality and not even use the good possible setting as yet ( super fine ) .\n",
      "7: ensure you get a large flash , 128 or 256 , some be sell with the large flash , 32 mb will do in a pinch but you 'll quickly want a large flash card as with any of the 4mp camera .\n",
      "8: bottom line , well make camera , easy to use , very flexible and powerful feature to include the ability to use external flash and lense / filter choice .\n",
      "9: i 'd highly recommend this camera for anyone who be look for excellent quality picture and a combination of ease of use and the flexibility to get advanced with many option to adjust if you like .\n",
      "10: great job canon !\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "reviews_clean = clean_text(reviews, remove_stopwords=False, min_token_length=1)\n",
    "print_dict(reviews_clean, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d7883",
   "metadata": {},
   "source": [
    "Next we will create a train and test split, we will hold aside 25% of the data for the test set.\n",
    "\n",
    "A test set is not really necessary for our non-ML approach, however we will split the data now in anticipation of the ML approach that we will try later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ebe9116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train records: 447\n",
      "y_train records: 447\n",
      "x_test records: 150\n",
      "y_test records: 150 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_percent = 0.25\n",
    "x_train, y_train, x_test, y_test = create_train_test_sets(reviews_clean, labels, test_percent, \n",
    "                                                          random_seed=42, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174cd5e",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we:\n",
    "    <li> Applied preprocessing steps to the review data </li>\n",
    "    <li> Split the data into training and test sets </li>   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790c1186",
   "metadata": {},
   "source": [
    "### 3. Extract relevant information\n",
    "\n",
    "In this step we want to first extract what features customers are commentning on in the reviews.\n",
    "\n",
    "To extract features I have implemented a custom function which returns all combinations of consecutive nouns within the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89b785",
   "metadata": {},
   "source": [
    "#### 3.1 Frequent features identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3015e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Get the noun phrases from a document using a method I found on Stack Overflow, this appears superior to\n",
    "    the spaCy noun_chunks methods\n",
    "    https://stackoverflow.com/questions/49564176/python-nltk-more-efficient-way-to-extract-noun-phrases\n",
    "    \"\"\"    \n",
    "    features_dict = defaultdict(int)\n",
    "    for i, text in enumerate(text_dict.values()):\n",
    "        if verbose and i%100 == 0 and i > 0:\n",
    "            print(f'Records processed: {i}')\n",
    "        pos = pos_tag(word_tokenize(text))\n",
    "        count = 0\n",
    "        half_chunk = \"\"\n",
    "        for word, tag in pos:\n",
    "            if re.match(r\"NN.*\", tag):\n",
    "                count+=1\n",
    "                if count>=1:\n",
    "                    half_chunk = half_chunk + word + \" \"\n",
    "            else:\n",
    "                half_chunk = half_chunk+\"---\"\n",
    "                count = 0\n",
    "        half_chunk = re.sub(r\"-+\",\"?\",half_chunk).split(\"?\")\n",
    "        half_chunk = [x.strip() for x in half_chunk if x!=\"\"]\n",
    "        \n",
    "        for chunk in half_chunk:\n",
    "            # Increment the dictionary\n",
    "            features_dict[chunk] += 1\n",
    "    \n",
    "    # Sort the dictionary\n",
    "    features_dict = sort_dict(features_dict, reverse=True)\n",
    "    \n",
    "    return features_dict\n",
    "\n",
    "def feature_pruning(text_dict, features_dict, features_list=[], min_support=3, min_percent=0.01, verbose=False):\n",
    "    \"\"\"\n",
    "    Prune features using p_support and keep features that appear in at least 1% of sentences\n",
    "    \"\"\"\n",
    "    # Apply p-support pruning\n",
    "    pruned_features_dict = features_dict.copy()\n",
    "    for k1, v1 in features_dict.items():\n",
    "        # Find single word features and the support\n",
    "        if len(k1.split())==1:\n",
    "            p_support = v1\n",
    "            if verbose:\n",
    "                print(f'feature {k1} support={p_support}')\n",
    "            # Calculate p_support by subtracting the number of times the single noun appears in other\n",
    "            #   noun_phrases\n",
    "            for k2, v2 in features_dict.items():\n",
    "                if len(k2.split())!=1:\n",
    "                    if k1 in k2:\n",
    "                        p_support -= v2\n",
    "                        if verbose:\n",
    "                            print(f'feature {k1} found in {k2}, updated support={p_support}') \n",
    "            # If the final p_support value < min_support, remove this feacture\n",
    "            if p_support < min_support:\n",
    "                pruned_features_dict.pop(k1, None)\n",
    "                if verbose:\n",
    "                    print(f'feature {k1} removed, support={p_support}')\n",
    "              \n",
    "    # Apply frequent feature pruning\n",
    "    features = []\n",
    "    for k, v in pruned_features_dict.items():\n",
    "        if v > int(len(text_dict) * min_percent):\n",
    "            features.append(k)\n",
    "            \n",
    "    return features\n",
    "\n",
    "def find_docs_with_features(text_dict, features):\n",
    "    \"\"\" \n",
    "    Identify which documents contain the features\n",
    "    \"\"\"\n",
    "    docs_containing_features = {}\n",
    "    doc_features = []\n",
    "    for k, v in text_dict.items():\n",
    "        doc_features = []\n",
    "        for feature in features:\n",
    "            if feature in v:\n",
    "                doc_features.append(feature)\n",
    "        if len(doc_features) > 0:\n",
    "            docs_containing_features[k] = doc_features\n",
    "    return docs_containing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bf2e601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 135\n",
      "camera: 116\n",
      "g3: 37\n",
      "picture: 36\n",
      "time: 23\n",
      "feature: 20\n",
      "flash: 19\n",
      "canon: 18\n",
      "photo: 15\n",
      "lens: 14\n",
      "image: 13\n",
      "Total features: 753\n"
     ]
    }
   ],
   "source": [
    "# Extract the features\n",
    "features_dict = get_features(x_train, verbose=False)\n",
    "print_dict(features_dict, n=10)\n",
    "print(f'Total features: {len(features_dict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e266292e",
   "metadata": {},
   "source": [
    "To reduce the number of features, I have implemented the p-support and feature frequency pruning methods described by Hu and Liu (2004).\n",
    "\n",
    "Specifically, single word features must have a p-support of at least 3 and all features must appear in at least 1% of sentences in order to be retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4598f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['camera', 'g3', 'picture', 'time', 'feature', 'flash', 'canon', 'lens', 'image', 'use', 'viewfinder', 'point', 'g2', 'thing', 'review', 'lot', 'shot', 'research', 'battery life', 'result', 'moment', 'setting', 'slr', 'control', 'problem', 'range', 'card', 'canon g3', 'picture quality', 'exposure', 'light', 'year', 'something', 'photography', 'purchase', 'hand', 'lense', 'way', 'box', 'people', 'difference', 'ability', 'week', 'bit', 's330', 'color']\n",
      "Remaining features: 46\n"
     ]
    }
   ],
   "source": [
    "# Prune features\n",
    "features = feature_pruning(x_train, features_dict, min_support=3, min_percent=0.01)\n",
    "print(features)\n",
    "print(f'Remaining features: {len(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b076a620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109: ['camera']\n",
      "480: ['point', 'thing', 'range', 'something', 'photography']\n",
      "135: ['use']\n",
      "77: ['point', 'difference']\n",
      "396: ['camera']\n",
      "286: ['camera', 'g3', 'thing', 'lot', 'research', 'purchase', 'hand']\n",
      "10: ['canon']\n",
      "589: ['image', 'card']\n",
      "78: ['lens', 'range', 'lense']\n",
      "55: ['range']\n",
      "585: ['camera', 'g3', 'picture', 'canon', 'use', 'g2', 'battery life', 'canon g3', 'picture quality', 'way']\n"
     ]
    }
   ],
   "source": [
    "docs_containing_features_train = find_docs_with_features(x_train, features)\n",
    "docs_containing_features_test = find_docs_with_features(x_test, features)\n",
    "print_dict(docs_containing_features_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "296dead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.09% of sentences contain features\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(docs_containing_features_train)/len(x_train):.2%} of sentences contain features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb21d4a",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we have:\n",
    "    <li> Extracted potential features by identifying noun phrases </li>\n",
    "    <li> Reduced the number of potential features from 753 to 46 by implementing p_support, and keeping only potential features which appear in more than 1% of sentences </li>  \n",
    "    <li> We have then identified the sentences in the training and test sets that contain the identified features </li>\n",
    "    <li> We have found that 80% of the sentences in our training set contain features </li>\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25662c22",
   "metadata": {},
   "source": [
    "#### 3.2 Opinion words extraction\n",
    "Now we will only consider those sentences that we have identified as containing features. As per Hu and Liu (2004), we consider adjectives to be potential opinion words.\n",
    "\n",
    "To identify candidate opinion words, we will loop through the sentences that contain features, extract the adjectives and store these in a dictionary.\n",
    "\n",
    "We allocate opinion words to the closest feature. In this way it is possible for features to have multiple opinion words. Additionally, opinion words equidistant from multiple features can be allocated to multiple features, however this appears to be rare.\n",
    "\n",
    "We set a parameter, max_feature_distance, which defines the maximum allowable distance between an opinion word and a feature. The rationale is that the closer an opinion word is to a feature, the more likely that the opinion word pertains to that feature. Although this might not always be the case and long range dependencies may exist, this seems a reasonable assumption for our simplistic model.\n",
    "\n",
    "If this threshold cannot be met for any of the identified features, then an opinion word is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4069b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_and_allocate_opinion_words(text_dict, docs_containing_features, max_feature_distance=3, verbose=False):\n",
    "    \"\"\"\n",
    "    Identify opinion words and allocate them to nearby features in a text\n",
    "    \"\"\"\n",
    "\n",
    "    opinion_words_dict = defaultdict(list)\n",
    "    for k, v in docs_containing_features.items():\n",
    "        features_dict = defaultdict(list)\n",
    "        adjectives_list = []\n",
    "        features_list = []\n",
    "\n",
    "        text = text_dict[k]\n",
    "        doc = nlp(text, disable=[\"ner\"]) \n",
    "\n",
    "        # Find adjectives and their positions \n",
    "        for token in doc:\n",
    "            if token.pos_=='ADJ':\n",
    "                adjectives_list.append((token.text, token.i))\n",
    "\n",
    "        # Search for the features in the text and find the positions\n",
    "        for feature in v:\n",
    "            pos = find_feature_pos(text, feature)\n",
    "            features_list.append((feature, pos))\n",
    "\n",
    "        # Allocate adjectives to nearest feature\n",
    "        for adj in adjectives_list:\n",
    "            min_feature_distance = np.inf\n",
    "            closest_feature = None\n",
    "            for feature in features_list:\n",
    "                distance = abs(feature[1] - adj[1])\n",
    "                if distance < min_feature_distance and distance <= max_feature_distance and distance != 0:\n",
    "                    min_feature_distance = distance\n",
    "                    closest_feature = feature[0]\n",
    "            if verbose:\n",
    "                print(f'Closest feature to {adj} is {closest_feature} with a token distance of {min_feature_distance} \\n')\n",
    "            if closest_feature is not None:\n",
    "                features_dict[closest_feature].append(adj[0])\n",
    "        if len(features_dict) > 0:\n",
    "            opinion_words_dict[k] = features_dict\n",
    "\n",
    "    return opinion_words_dict\n",
    "    \n",
    "def find_feature_pos(text, feature):\n",
    "    \"\"\"\n",
    "    Helper function to find feature position in a text\n",
    "    \"\"\"\n",
    "    text_split = text.split()\n",
    "    feature_split = feature.split()\n",
    "    len_text_split = len(text_split)\n",
    "    len_feature_split = len(feature_split)\n",
    "    \n",
    "    for i in range(len_text_split - len_feature_split + 1):\n",
    "        if text_split[i:i+len_feature_split] == feature_split:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db0646ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109: defaultdict(<class 'list'>, {'camera': ['great']})\n",
      "480: defaultdict(<class 'list'>, {'point': ['advanced'], 'photography': ['serious']})\n",
      "135: defaultdict(<class 'list'>, {'use': ['used']})\n",
      "77: defaultdict(<class 'list'>, {'point': ['more'], 'difference': ['moderate']})\n",
      "396: defaultdict(<class 'list'>, {'camera': ['first', 'digital']})\n",
      "286: defaultdict(<class 'list'>, {'camera': ['digital']})\n",
      "10: defaultdict(<class 'list'>, {'canon': ['great']})\n",
      "78: defaultdict(<class 'list'>, {'lens': ['extended'], 'lense': ['fast']})\n",
      "290: defaultdict(<class 'list'>, {'camera': ['great']})\n",
      "30: defaultdict(<class 'list'>, {'setting': ['automatic'], 'picture': ['bad']})\n",
      "463: defaultdict(<class 'list'>, {'g3': ['unnerving']})\n"
     ]
    }
   ],
   "source": [
    "opword_dict_train = identify_and_allocate_opinion_words(x_train, docs_containing_features_train, \n",
    "                                                        max_feature_distance=5, verbose=False)\n",
    "opword_dict_test = identify_and_allocate_opinion_words(x_test, docs_containing_features_test, \n",
    "                                                        max_feature_distance=5, verbose=False)\n",
    "print_dict(opword_dict_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be25f473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.26% of sentences contain features and opinion words\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(opword_dict_train)/len(x_train):.2%} of sentences contain features and opinion words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440ba4e",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we have:\n",
    "    <li> Identified opinion words as adjectives and allocated these opinion words to features using a simple distance method </li>\n",
    "    <li> Found that 55% of sentences have mention of features with opinion words </li>   \n",
    "</font>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3246aa62",
   "metadata": {},
   "source": [
    "#### 3.3 Orientation Identification for Opinion Words\n",
    "\n",
    "Hu and Liu (2004) utilise WordNet to determine the orientation of opinion words. I depart from this approach and identify the orientation of opinion words by leveraging the word vectors prodivded by spaCy tokens.\n",
    "\n",
    "For each opinion word, I compare its vector representation to the vector representations of the words \"positive\" and \"negative\".\n",
    "\n",
    "If the opinion word is closer to \"positive\" as measured by cosine similarity, then the orientation of the word is deemed to be positive. Conversely, if the opinion word is closer to \"negative\", then the orientation of the word is deemed to be negative. If the cosine similarities to both positive and negative are similar (less than 10% relative difference, chosen arbitrarily), then the orientation is deemed to be neutral.\n",
    "\n",
    "As demonstrated in the following cells, this method appears to work very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfa290af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(text, verbose=False):\n",
    "    \"\"\" \n",
    "    Returns polarity of a document by comparing the cosine similarity of a token \n",
    "    to \"negative\" and \"positive\"\n",
    "    \n",
    "    Returns:\n",
    "        int 1: positive, 0: neutral, -1: negative\n",
    "    \"\"\"\n",
    "    DIFFERENCE_THRESHOLD = 0.1\n",
    "    MIN_SIMILARITY = 0.1\n",
    "    \n",
    "    doc = nlp(text, disable=[\"ner\"])\n",
    "    if np.all(doc.vector):\n",
    "        doc_pos = nlp(\"positive\", disable=[\"ner\"])\n",
    "        doc_neg = nlp(\"negative\", disable=[\"ner\"])\n",
    "\n",
    "        sim_pos = doc.similarity(doc_pos)\n",
    "        sim_neg = doc.similarity(doc_neg)\n",
    "        if sim_pos > 0 and sim_neg > 0:\n",
    "            relative_diff = sim_pos/sim_neg-1\n",
    "        else:\n",
    "            relative_diff = 0\n",
    "\n",
    "        if relative_diff > DIFFERENCE_THRESHOLD and sim_pos > MIN_SIMILARITY:\n",
    "            sentiment = 1\n",
    "        elif relative_diff < -DIFFERENCE_THRESHOLD and sim_neg > MIN_SIMILARITY:\n",
    "            sentiment = -1\n",
    "        else: \n",
    "            sentiment = 0\n",
    "\n",
    "        if verbose:\n",
    "            print(f'{doc} -> {doc_pos} {sim_pos}')\n",
    "            print(f'{doc} -> {doc_neg} {sim_neg}')\n",
    "            if sentiment == 1:\n",
    "                print(f\"{doc} classified as POSITIVE\")\n",
    "            elif sentiment == -1:\n",
    "                print(f\"{doc} classified as NEGATIVE\")\n",
    "            else:\n",
    "                print(f\"{doc} classified as NEUTRAL\")\n",
    "    else:\n",
    "        sentiment = 0\n",
    "        if verbose:\n",
    "            print(f\"{doc} has no vector, classified as NEUTRAL\")\n",
    "        \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712343e2",
   "metadata": {},
   "source": [
    "#### Below is a demonstration of the polarity function on a range of words\n",
    "\n",
    "As expected, words such as \"amazing\", and \"great\" are given a positive orientation and words such as \"terrible\" and \"rubbish\" are given a negative orientation. Words such as \"average\" and \"ok\" are classed as neutral. Non-existent words such as \"scoozle\", which I made up, do not have a prebuilt spaCy vector representation and are deemed as neutral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b34e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazing -> positive 0.29383947128808274\n",
      "amazing -> negative 0.15883798557452\n",
      "amazing classified as POSITIVE\n",
      "\n",
      "great -> positive 0.3911600082252871\n",
      "great -> negative 0.23636989022567528\n",
      "great classified as POSITIVE\n",
      "\n",
      "terrible -> positive 0.28007942392719387\n",
      "terrible -> negative 0.3913616946409252\n",
      "terrible classified as NEGATIVE\n",
      "\n",
      "rubbish -> positive 0.13967908330449005\n",
      "rubbish -> negative 0.24332614796946453\n",
      "rubbish classified as NEGATIVE\n",
      "\n",
      "average -> positive 0.3507661092170427\n",
      "average -> negative 0.36584300761165206\n",
      "average classified as NEUTRAL\n",
      "\n",
      "ok -> positive 0.2533984654352536\n",
      "ok -> negative 0.270677459132954\n",
      "ok classified as NEUTRAL\n",
      "\n",
      "scoozle has no vector, classified as NEUTRAL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of the polarity function\n",
    "words= [\"amazing\", \"great\", \"terrible\", \"rubbish\", \"average\", \"ok\", \"scoozle\"]\n",
    "\n",
    "for word in words:\n",
    "    p = polarity(word, True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57360d",
   "metadata": {},
   "source": [
    "#### 3.4 Predicting the Orientations of Opinion Sentences\n",
    "\n",
    "For each sentence containing opinion words, we will assign a polarity to each opinion word alloacted to each feature using the method described above. We will save these results in a new dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88feeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_polarity(opword_dict):\n",
    "    \"\"\" \n",
    "    Get polarity for opinion words in a sentence\n",
    "    \"\"\"\n",
    "    polarity_dict = defaultdict(list)\n",
    "    for k1, v1 in opword_dict.items():\n",
    "        feature_dict = defaultdict(list)\n",
    "        for k2, v2 in v1.items():\n",
    "            cum_polarity = 0\n",
    "            for opword in v2:\n",
    "                cum_polarity += polarity(opword)\n",
    "            feature_dict[k2] = cum_polarity\n",
    "        polarity_dict[k1] = feature_dict\n",
    "    return polarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a60f84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109: defaultdict(<class 'list'>, {'camera': 1})\n",
      "480: defaultdict(<class 'list'>, {'point': 1, 'photography': 0})\n",
      "135: defaultdict(<class 'list'>, {'use': -1})\n",
      "77: defaultdict(<class 'list'>, {'point': 1, 'difference': 0})\n",
      "396: defaultdict(<class 'list'>, {'camera': 0})\n",
      "286: defaultdict(<class 'list'>, {'camera': -1})\n",
      "10: defaultdict(<class 'list'>, {'canon': 1})\n",
      "78: defaultdict(<class 'list'>, {'lens': 1, 'lense': 1})\n",
      "290: defaultdict(<class 'list'>, {'camera': 1})\n",
      "30: defaultdict(<class 'list'>, {'setting': 0, 'picture': -1})\n",
      "463: defaultdict(<class 'list'>, {'g3': -1})\n"
     ]
    }
   ],
   "source": [
    "polarity_dict_train = calculate_polarity(opword_dict_train)\n",
    "polarity_dict_test = calculate_polarity(opword_dict_test)\n",
    "print_dict(polarity_dict_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0620bb47",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we have:\n",
    "    <li> Used word vectors and cosine similarity to determine the polarity of the opinion words allocated to the features in the reviews </li>\n",
    "</font>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714c158",
   "metadata": {},
   "source": [
    "### 4. Apply relevant algorithms\n",
    "\n",
    "We will now create summaries for product features by iterating through all the identified features, and summing the polarity of the opinion words for each of those features.\n",
    "\n",
    "We construct summaries of the form:\n",
    "\n",
    "- Product Name  \n",
    "    - Feature Name  \n",
    "        - Positive: # of positive opinion words\n",
    "        - Negative: # of negative opinion words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f84f20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def create_summary_review(product_name, polarity_dict, max_features=5):\n",
    "    \"\"\" \n",
    "    Summarise the review for a product \n",
    "    \"\"\"\n",
    "    pos_dict = defaultdict(int)\n",
    "    neg_dict = defaultdict(int)\n",
    "    counts_dict = defaultdict(int)\n",
    "    \n",
    "    for k1, v1 in polarity_dict.items():\n",
    "        for k2, v2 in v1.items():\n",
    "            if v2 > 0:\n",
    "                counts_dict[k2] += 1\n",
    "                pos_dict[k2] += 1\n",
    "            elif v2 < 0:\n",
    "                counts_dict[k2] += 1\n",
    "                neg_dict[k2] += 1\n",
    "                \n",
    "    # Sort the dictionary\n",
    "    counts_dict = sort_dict(counts_dict, reverse=True)   \n",
    "    \n",
    "    print(f'Product: {product_name}')\n",
    "    for i, k in enumerate(counts_dict.keys()):\n",
    "        if i > max_features:\n",
    "            break\n",
    "        print(f'  Feature: {k}')\n",
    "        print(f'     Positive: {pos_dict[k]}')\n",
    "        print(f'     Negative: {neg_dict[k]} \\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a814e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Canon G3\n",
      "  Feature: camera\n",
      "     Positive: 39\n",
      "     Negative: 14 \n",
      "\n",
      "  Feature: use\n",
      "     Positive: 22\n",
      "     Negative: 3 \n",
      "\n",
      "  Feature: picture\n",
      "     Positive: 13\n",
      "     Negative: 8 \n",
      "\n",
      "  Feature: flash\n",
      "     Positive: 5\n",
      "     Negative: 6 \n",
      "\n",
      "  Feature: image\n",
      "     Positive: 6\n",
      "     Negative: 5 \n",
      "\n",
      "  Feature: g3\n",
      "     Positive: 6\n",
      "     Negative: 4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_summary_review(product, polarity_dict_train, max_features=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3322aca",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we have:\n",
    "    <li> Generated a feature level summary for a given product, detailing the number of positive and negative opinion words associated with each feature </li>\n",
    "</font>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f13f10",
   "metadata": {},
   "source": [
    "### 5. Evaluation\n",
    "\n",
    "In this section we will evaluate the performance of our algorithm so far.\n",
    "\n",
    "We will assess performance in two areas:\n",
    "1. How well our algorithm identifies product features \n",
    "2. How well our algorithm has identifies sentiment, both in terms of detection and orientation\n",
    "\n",
    "We will use precision, recall (and accuracy for sentiment orientation) as performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d28a7f",
   "metadata": {},
   "source": [
    "#### 5.1 Feature identification\n",
    "\n",
    "Firstly, we want to know how well our algorithm identifies features in the reviews.\n",
    "\n",
    "As there are many possible features, I have only considered those features that are common between the ground truth labels and those we have discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b1e7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_target_df_from_labels(y_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Create a pandas dataframe of target variables given target labels sourced from the original data\n",
    "    \"\"\"\n",
    "    features_set = set()\n",
    "    target_dict = defaultdict(list)\n",
    "\n",
    "    # Firstly, collect all the features in a set\n",
    "    for k, v in y_dict.items():\n",
    "        v_split = v.split(',')\n",
    "        if len(v_split) > 0:\n",
    "            for x in v_split:\n",
    "                k = x[:x.find('[')].strip()\n",
    "                if k != '':\n",
    "                    features_set.add(k)\n",
    "                    \n",
    "    # Create tabular data\n",
    "    for k, v in y_dict.items():\n",
    "        v_split = v.split(',')\n",
    "        items = [(x[:x.find('[')].strip(), x[x.find('[')+1:x.find(']')].strip()) for x in v_split]\n",
    "        for i in items:\n",
    "            if len(i[0]) > 0:\n",
    "                target_dict[i[0]].append(1)\n",
    "        for j in [f for f in features_set if f not in [i[0] for i in items]]:\n",
    "            target_dict[j].append(0)\n",
    " \n",
    "    if verbose:\n",
    "        print('Target labels and volumes:')\n",
    "        for k in target_dict.keys():\n",
    "            print(k, len(target_dict[k]))\n",
    "                \n",
    "    return pd.DataFrame(target_dict)\n",
    "\n",
    "def create_feature_target_df_from_model(x_dict, docs_containing_features, polarity_dict, features, verbose=False):\n",
    "    \"\"\" \n",
    "    Create a target df from the features identified in our analysis \n",
    "    \"\"\"\n",
    "    target_dict = defaultdict(list)\n",
    "    keys = []\n",
    "    for k in x_dict.keys():\n",
    "        if k in docs_containing_features.keys():\n",
    "            for feature in docs_containing_features[k]:\n",
    "                target_dict[feature].append(1)\n",
    "            for feature in [f for f in features if f not in docs_containing_features[k]]:\n",
    "                target_dict[feature].append(0)\n",
    "        else:\n",
    "            for feature in features:\n",
    "                target_dict[feature].append(0)\n",
    "                \n",
    "    if verbose:\n",
    "        for k in target_dict.keys():\n",
    "            print(k, len(target_dict[k]))\n",
    "        \n",
    "    return pd.DataFrame(target_dict)\n",
    "\n",
    "def performance_metrics_feat(y_df, y_pred_df, feature_level=False):\n",
    "    \"\"\"\n",
    "    Calculate precision and recall\n",
    "    \"\"\"\n",
    "    performance_dict = defaultdict(list)\n",
    "    \n",
    "    # Only keep features present in both datasets\n",
    "    shared_features = [x for x in y_pred_df.columns.to_list() if x in y_df.columns.to_list()]\n",
    "    y_df = y_df[shared_features]\n",
    "    y_pred_df = y_pred_df[shared_features]\n",
    "    \n",
    "    if feature_level:\n",
    "        for feature in shared_features:\n",
    "            count = y_df[feature].sum()\n",
    "            precision = precision_score(y_df[feature], y_pred_df[feature])\n",
    "            recall = recall_score(y_df[feature], y_pred_df[feature])\n",
    "            performance_dict['feature'].append(feature)\n",
    "            performance_dict['count'].append(count)\n",
    "            performance_dict['precision'].append(precision)\n",
    "            performance_dict['recall'].append(recall)\n",
    "    else:\n",
    "        precision = precision_score(y_df, y_pred_df, average='weighted')\n",
    "        recall = recall_score(y_df, y_pred_df, average='weighted')\n",
    "        performance_dict['precision'].append(precision)\n",
    "        performance_dict['recall'].append(recall)\n",
    "        \n",
    "    return pd.DataFrame(performance_dict)\n",
    "\n",
    "def performance_metrics_feat_combined(product, y_train_df, y_train_pred_df, y_test_df, y_test_pred_df):\n",
    "    \"\"\"\n",
    "    Combine train and test features metrics to form one unified dataframe\n",
    "    \"\"\" \n",
    "    COLUMNS = ['precision_train', 'recall_train', 'precision_test', 'recall_test']\n",
    "    train_metrics = performance_metrics_feat(y_train_df, y_train_pred_df, feature_level=False)\n",
    "    test_metrics = performance_metrics_feat(y_test_df, y_test_pred_df, feature_level=False)\n",
    "    combined_metrics = pd.concat([train_metrics, test_metrics], axis=1)\n",
    "    combined_metrics['product'] = product\n",
    "    combined_metrics.columns = COLUMNS + ['product']\n",
    "    \n",
    "    return combined_metrics[['product'] + COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b9613ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "y_train_feat = create_feature_target_df_from_labels(y_train)\n",
    "y_train_pred_feat = create_feature_target_df_from_model(x_train, docs_containing_features_train, \n",
    "                                                            polarity_dict_train, features)\n",
    "y_test_feat = create_feature_target_df_from_labels(y_test)\n",
    "y_test_pred_feat = create_feature_target_df_from_model(x_test, docs_containing_features_test, \n",
    "                                                               polarity_dict_test, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51caaaf",
   "metadata": {},
   "source": [
    "We find that our algorithm has a precision of about 0.31 and recall of 0.88 on the test set.\n",
    "\n",
    "This means that on averages it detects features correctly 31% of the time, and it captures 88% of all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f156e6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canon G3</td>\n",
       "      <td>0.299438</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.309133</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product  precision_train  recall_train  precision_test  recall_test\n",
       "0  Canon G3         0.299438          0.83        0.309133     0.880952"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate performance\n",
    "perf_feat = performance_metrics_feat_combined(product, y_train_feat, y_train_pred_feat, \n",
    "                                                  y_test_feat, y_test_pred_feat)\n",
    "perf_feat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc4ed0",
   "metadata": {},
   "source": [
    "#### 5.2 Analysis of sentiment\n",
    "\n",
    "In this section we will evaluate how well our model predicts sentiment at the sentence level.\n",
    "\n",
    "We measure how well the algorithm captures sentiment bearing sentences through precision and recall, and orientation performance via accuracy.\n",
    "\n",
    "When considering orientation, a sentence is deemed to have positive sentiment is the sum of the orientation values is positive, negative sentiment if the sum of the orientation values is negative, and neutral if the sum is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf40218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentiment_target_df_from_labels(y_dict):\n",
    "    \"\"\"\n",
    "    Create a pandas dataframe of target variables given target labels sourced from the original data\n",
    "    \"\"\"\n",
    "    # Create dicts to store sentiment bearing sentence binary flags and orientations\n",
    "    sbs_dict = {}\n",
    "    orientation_dict = {}\n",
    "    \n",
    "    # Create tabular data\n",
    "    for k, v in y_dict.items():\n",
    "        v_split = v.split(',')\n",
    "        items = [x[x.find('[')+1:x.find(']')].strip() for x in v_split]\n",
    "        cumsum = 0\n",
    "        sbs_dict[k] = 0\n",
    "        for i in items:\n",
    "            if len(i) > 0:\n",
    "                sbs_dict[k] = 1\n",
    "                try:\n",
    "                    if i==\"+\" or int(i) > 0:\n",
    "                        cumsum += 1\n",
    "                    elif i==\"-\" or int(i) < 0:\n",
    "                        cumsum -= 1\n",
    "                except:\n",
    "                    pass\n",
    "        if cumsum > 0:\n",
    "            orientation_dict[k] = 1\n",
    "        elif cumsum < 0:\n",
    "            orientation_dict[k] = -1\n",
    "        else:\n",
    "            orientation_dict[k] = 0\n",
    "         \n",
    "    # Create target df by combining sbs and orientation DataFrames\n",
    "    sbs_df = pd.DataFrame(sbs_dict, index=[0]).T\n",
    "    sbs_df.columns = ['sentiment']\n",
    "    orientation_df = pd.DataFrame(orientation_dict, index=[0]).T\n",
    "    orientation_df.columns = ['orientation']\n",
    "    target_df = pd.concat([sbs_df, orientation_df], axis=1)\n",
    "    \n",
    "    return target_df\n",
    "\n",
    "def create_sentiment_target_df_from_model(x_train, polarity_dict):\n",
    "    \"\"\" \n",
    "    Create a sentiment df from the features identified in our analysis \n",
    "    \"\"\"\n",
    "    # Create dicts to store sentiment bearing sentence binary flags and orientations\n",
    "    sbs_dict = {}\n",
    "    orientation_dict = {}\n",
    "\n",
    "    for k in x_train.keys():\n",
    "        if k in polarity_dict.keys():\n",
    "            sbs_dict[k] = 1\n",
    "            cum_sum = 0\n",
    "            for value in polarity_dict[k].values():\n",
    "                cum_sum += value\n",
    "            if cum_sum > 0:\n",
    "                orientation_dict[k] = 1\n",
    "            elif cum_sum < 0:\n",
    "                orientation_dict[k] = -1\n",
    "            else:\n",
    "                orientation_dict[k] = 0    \n",
    "        else:\n",
    "            orientation_dict[k] = 0\n",
    "            sbs_dict[k] = 0\n",
    "            \n",
    "    # Create target df by combining sbs and orientation DataFrames\n",
    "    sbs_df = pd.DataFrame(sbs_dict, index=[0]).T\n",
    "    sbs_df.columns = ['sentiment']\n",
    "    orientation_df = pd.DataFrame(orientation_dict, index=[0]).T\n",
    "    orientation_df.columns = ['orientation']\n",
    "    target_df = pd.concat([sbs_df, orientation_df], axis=1)  \n",
    "    \n",
    "    return target_df\n",
    "\n",
    "def performance_metrics_sentiment(y_df, y_pred_df):\n",
    "    \"\"\"\n",
    "    Calculate precision and recall\n",
    "    \"\"\"\n",
    "    performance_dict = defaultdict(list)\n",
    "    precision = precision_score(y_df['sentiment'], y_pred_df['sentiment'], average='weighted')\n",
    "    recall = recall_score(y_df['sentiment'], y_pred_df['sentiment'], average='weighted')\n",
    "    accuracy = accuracy_score(y_df['orientation'], y_pred_df['orientation'])\n",
    "    performance_dict['precision'].append(precision)\n",
    "    performance_dict['recall'].append(recall)\n",
    "    performance_dict['orientation_accuracy'].append(accuracy)\n",
    "    return pd.DataFrame(performance_dict)\n",
    "\n",
    "def performance_metrics_sentiment_combined(product, y_train_df, y_train_pred_df, y_test_df, y_test_pred_df):\n",
    "    \"\"\"\n",
    "    Combine train and test sentiment metrics to form one unified dataframe\n",
    "    \"\"\"\n",
    "    COLUMNS = ['precision_train', 'recall_train', 'accuracy_train', 'precision_test', 'recall_test', 'accuracy_test']\n",
    "    train_metrics = performance_metrics_sentiment(y_train_df, y_train_pred_df)\n",
    "    test_metrics = performance_metrics_sentiment(y_test_df, y_test_pred_df)\n",
    "    combined_metrics = pd.concat([train_metrics, test_metrics], axis=1)\n",
    "    combined_metrics['product'] = product\n",
    "    combined_metrics.columns = COLUMNS + ['product']\n",
    "    \n",
    "    return combined_metrics[['product'] + COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6935302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "y_train_sentiment = create_sentiment_target_df_from_labels(y_train)\n",
    "y_train_pred_sentiment = create_sentiment_target_df_from_model(x_train, polarity_dict_train)\n",
    "y_test_sentiment = create_sentiment_target_df_from_labels(y_test)\n",
    "y_test_pred_sentiment = create_sentiment_target_df_from_model(x_test, polarity_dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948010b",
   "metadata": {},
   "source": [
    "We find that our algorithm has a precision of about 0.54, recall of 0.53 and accuracy of 0.49 on the test set.\n",
    "\n",
    "This means that on averages it detects senteniment bearing sentences 54% of the time, it captures 53% of all sentiment bearing sentences, and it predicts orientation correctly 49% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "198ead99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canon G3</td>\n",
       "      <td>0.623545</td>\n",
       "      <td>0.574944</td>\n",
       "      <td>0.608501</td>\n",
       "      <td>0.537229</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.493333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product  precision_train  recall_train  accuracy_train  precision_test  \\\n",
       "0  Canon G3         0.623545      0.574944        0.608501        0.537229   \n",
       "\n",
       "   recall_test  accuracy_test  \n",
       "0     0.533333       0.493333  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate performance\n",
    "perf_sentiment = performance_metrics_sentiment_combined(product, y_train_sentiment, y_train_pred_sentiment, \n",
    "                                       y_test_sentiment, y_test_pred_sentiment)\n",
    "perf_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c10266",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we have:\n",
    "    <li> Examined the performance of our algorithm in terms of feature identification and sentiment, using precision, recall and accuracy metrics </li>\n",
    "    <li> Found that the performance of our algorithm leaves a lot to be desired, and is far from human level performance </li>   \n",
    "</font>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fc5c1",
   "metadata": {},
   "source": [
    "#### 5.3 Creating an NLP pipeline and analysing more products\n",
    "In this section we will create a pipeline that orchestrates all of the previous steps in a single function.\n",
    "\n",
    "We will use this pipeline to replicate the analysis for multiple products. All parameters used in pervious steps will be retain their settings for this analysis for comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5006c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_single_product(file, \n",
    "                                product=\"\",\n",
    "                                test_percent=0.25, \n",
    "                                remove_stopwords=False, \n",
    "                                min_token_length=1,\n",
    "                                min_support=3,\n",
    "                                min_percent=0.01, \n",
    "                                max_feature_distance=5,\n",
    "                                max_features_review=5,\n",
    "                                random_seed=42,\n",
    "                                print_review=True,\n",
    "                                verbose=False):\n",
    "    \"\"\"\n",
    "    Run the whole NLP pipeline for a single product\n",
    "    \"\"\"\n",
    "    data = read_in(single_file=file)\n",
    "    labels, reviews, other, data_clean = create_dicts(data)\n",
    "    \n",
    "    # Data preprocessing\n",
    "    reviews_clean = clean_text(reviews, remove_stopwords=remove_stopwords, min_token_length=min_token_length)\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = create_train_test_sets(reviews_clean, labels, test_percent, \n",
    "                                                              random_seed=random_seed, verbose=verbose)\n",
    "    \n",
    "    # Extract relevant information\n",
    "    features_dict = get_features(x_train, verbose=verbose)\n",
    "    \n",
    "    features = feature_pruning(x_train, features_dict, min_support=min_support, min_percent=min_percent)\n",
    "    \n",
    "    docs_containing_features_train = find_docs_with_features(x_train, features)\n",
    "    docs_containing_features_test = find_docs_with_features(x_test, features)\n",
    "    opword_dict_train = identify_and_allocate_opinion_words(x_train, docs_containing_features_train, \n",
    "                                                            max_feature_distance=max_feature_distance,\n",
    "                                                            verbose=verbose) \n",
    "    opword_dict_test = identify_and_allocate_opinion_words(x_test, docs_containing_features_test, \n",
    "                                                           max_feature_distance=max_feature_distance,\n",
    "                                                           verbose=verbose) \n",
    "        \n",
    "    polarity_dict_train = calculate_polarity(opword_dict_train)\n",
    "    polarity_dict_test = calculate_polarity(opword_dict_test)\n",
    "    \n",
    "    # Apply the algorithm\n",
    "    if print_review:\n",
    "        create_summary_review(product + ' Train', polarity_dict_train, max_features=max_features_review)\n",
    "        create_summary_review(product + ' Test', polarity_dict_test, max_features=max_features_review)\n",
    "        \n",
    "    # Evaluation - Product features\n",
    "    y_train_feat = create_feature_target_df_from_labels(y_train)\n",
    "    y_train_pred_feat = create_feature_target_df_from_model(x_train, docs_containing_features_train, \n",
    "                                                                polarity_dict_train, features)\n",
    "    \n",
    "    y_test_feat = create_feature_target_df_from_labels(y_test)\n",
    "    y_test_pred_feat = create_feature_target_df_from_model(x_test, docs_containing_features_test, \n",
    "                                                                polarity_dict_test, features)\n",
    "    \n",
    "    perf_feat = performance_metrics_feat_combined(product, y_train_feat, y_train_pred_feat, \n",
    "                                                  y_test_feat, y_test_pred_feat)\n",
    "    \n",
    "    # Evaluation - Sentiment\n",
    "    y_train_sentiment = create_sentiment_target_df_from_labels(y_train)\n",
    "    y_train_pred_sentiment = create_sentiment_target_df_from_model(x_train, polarity_dict_train)\n",
    "\n",
    "    y_test_sentiment = create_sentiment_target_df_from_labels(y_test)\n",
    "    y_test_pred_sentiment = create_sentiment_target_df_from_model(x_test, polarity_dict_test)\n",
    "\n",
    "    perf_sentiment = performance_metrics_sentiment_combined(product, y_train_sentiment, y_train_pred_sentiment, \n",
    "                                                            y_test_sentiment, y_test_pred_sentiment)\n",
    "    \n",
    "    return perf_feat, perf_sentiment\n",
    "\n",
    "def create_mean_perf(perf_df_all, sentiment=False):\n",
    "    \"\"\"\n",
    "    Calculate mean metrics to add as an average row\n",
    "    \"\"\"\n",
    "    mean_dict = {}\n",
    "    mean_perf = perf_df_all.mean(numeric_only=True, axis=0)\n",
    "    mean_dict['product'] = 'Average'\n",
    "    mean_dict['precision_train'] = mean_perf['precision_train']\n",
    "    mean_dict['recall_train'] = mean_perf['recall_train']\n",
    "    if sentiment:\n",
    "        mean_dict['accuracy_train'] = mean_perf['accuracy_train']\n",
    "    mean_dict['precision_test'] = mean_perf['precision_test']\n",
    "    mean_dict['recall_test'] = mean_perf['recall_test']\n",
    "    if sentiment:\n",
    "        mean_dict['accuracy_test'] = mean_perf['accuracy_test']\n",
    "    return mean_dict\n",
    "\n",
    "def run_pipeline_multiple_products(file_list, \n",
    "                                   product_list,\n",
    "                                   test_percent=0.25, \n",
    "                                   remove_stopwords=False, \n",
    "                                   min_token_length=1,\n",
    "                                   min_support=3,\n",
    "                                   min_percent=0.01, \n",
    "                                   max_feature_distance=5,\n",
    "                                   max_features_review=5,\n",
    "                                   random_seed=42,\n",
    "                                   print_review=False,\n",
    "                                   verbose=False):\n",
    "    \"\"\"\n",
    "    Run the NLP pipeline for multiple products\n",
    "    \"\"\"\n",
    "    if len(file_list) != len(product_list):\n",
    "        raise ValueError(\"The number of files and product names must match\")\n",
    "        \n",
    "    perf_feat_all = pd.DataFrame()\n",
    "    perf_sentiment_all = pd.DataFrame()\n",
    "    \n",
    "    for i, file in enumerate(file_list):\n",
    "        print(f'Running pipeline for {product_list[i]}')\n",
    "        perf_feat, perf_sentiment = run_pipeline_single_product(file, \n",
    "                                                                product=product_list[i],\n",
    "                                                                test_percent=test_percent, \n",
    "                                                                remove_stopwords=remove_stopwords, \n",
    "                                                                min_token_length=min_token_length,\n",
    "                                                                min_support=min_support,\n",
    "                                                                min_percent=min_percent, \n",
    "                                                                max_feature_distance=max_feature_distance,\n",
    "                                                                max_features_review=max_features_review,\n",
    "                                                                random_seed=random_seed,\n",
    "                                                                print_review=print_review,\n",
    "                                                                verbose=verbose)\n",
    "        # Append the dataframes\n",
    "        perf_feat_all = perf_feat_all.append(perf_feat)\n",
    "        perf_sentiment_all = perf_sentiment_all.append(perf_sentiment)\n",
    "        \n",
    "    \n",
    "    # Add averages\n",
    "    perf_feat_all = perf_feat_all.append(create_mean_perf(perf_feat_all), ignore_index=True)\n",
    "    perf_sentiment_all = perf_sentiment_all.append(create_mean_perf(perf_sentiment_all, sentiment=True), \n",
    "                                                   ignore_index=True)\n",
    "    return perf_feat_all, perf_sentiment_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254bc150",
   "metadata": {},
   "source": [
    "Now let's run the pipeline for the following 9 products:\n",
    "- Apex AD2600 Progressive-scan DVD player\n",
    "- Creative Labs Nomad Jukebox Zen Xtra 40GB\n",
    "- Hitachi Router\n",
    "- Nikon coolpix 4300\n",
    "- Diaper Champ\n",
    "- Nokia 6600\n",
    "- iPod\n",
    "- Linksys Router\n",
    "- Norton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16fe1bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for DVD player\n",
      "Running pipeline for MP3 player\n",
      "Running pipeline for Hitachi router\n",
      "Running pipeline for Nikon coolpix\n",
      "Running pipeline for Diaper Champ\n",
      "Running pipeline for Nokia 6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geoff\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for iPod\n",
      "Running pipeline for Linksys Router\n",
      "Running pipeline for Norton\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_list = ['data/Customer_review_data/Apex AD2600 Progressive-scan DVD player.txt',\n",
    "             'data/Customer_review_data/Creative Labs Nomad Jukebox Zen Xtra 40GB.txt',\n",
    "             'data/Customer_review_data/Nikon coolpix 4300.txt',\n",
    "             'data/Reviews-9-products/Hitachi router.txt',\n",
    "             'data/Reviews-9-products/Diaper Champ.txt',\n",
    "             'data/Reviews-9-products/Nokia 6600.txt',\n",
    "             'data/Reviews-9-products/ipod.txt',\n",
    "             'data/Reviews-9-products/Linksys Router.txt',\n",
    "             'data/Reviews-9-products/norton.txt']\n",
    "\n",
    "product_list = ['DVD player',\n",
    "                'MP3 player',\n",
    "                'Hitachi router',\n",
    "                'Nikon coolpix',\n",
    "                'Diaper Champ',\n",
    "                'Nokia 6600',\n",
    "                'iPod',\n",
    "                'Linksys Router',\n",
    "                'Norton']\n",
    "\n",
    "perf_feat_all, perf_sentiment_all = run_pipeline_multiple_products(file_list, product_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe49d092",
   "metadata": {},
   "source": [
    "Observing feature identification - the algorithm achieves an average test set precision of 0.33 and an average test set recall of 0.85.\n",
    "\n",
    "These results vary widely among the products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc76b688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DVD player</td>\n",
       "      <td>0.257247</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.163228</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP3 player</td>\n",
       "      <td>0.379275</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.335324</td>\n",
       "      <td>0.860759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hitachi router</td>\n",
       "      <td>0.440116</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.271288</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nikon coolpix</td>\n",
       "      <td>0.544922</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diaper Champ</td>\n",
       "      <td>0.343283</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.310608</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nokia 6600</td>\n",
       "      <td>0.380410</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iPod</td>\n",
       "      <td>0.296984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linksys Router</td>\n",
       "      <td>0.190587</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.272619</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Norton</td>\n",
       "      <td>0.251492</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.293357</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.342702</td>\n",
       "      <td>0.864020</td>\n",
       "      <td>0.325066</td>\n",
       "      <td>0.848826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product  precision_train  recall_train  precision_test  recall_test\n",
       "0      DVD player         0.257247      0.971429        0.163228     0.846154\n",
       "1      MP3 player         0.379275      0.836735        0.335324     0.860759\n",
       "2  Hitachi router         0.440116      0.876543        0.271288     0.681818\n",
       "3   Nikon coolpix         0.544922      0.802632        0.388889     0.733333\n",
       "4    Diaper Champ         0.343283      0.836735        0.310608     0.913043\n",
       "5      Nokia 6600         0.380410      0.786325        0.319444     0.766667\n",
       "6            iPod         0.296984      1.000000        0.570833     1.000000\n",
       "7  Linksys Router         0.190587      0.837209        0.272619     0.928571\n",
       "8          Norton         0.251492      0.828571        0.293357     0.909091\n",
       "9         Average         0.342702      0.864020        0.325066     0.848826"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_feat_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c34e3c",
   "metadata": {},
   "source": [
    "Observing sentiment - the algorithm achieves an average test set precision of 0.63, average test set recall of 0.60, and an average orientation accuracy of 0.57.\n",
    "\n",
    "Again, these results vary widely among the products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19c0ae50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DVD player</td>\n",
       "      <td>0.619350</td>\n",
       "      <td>0.617329</td>\n",
       "      <td>0.536101</td>\n",
       "      <td>0.551806</td>\n",
       "      <td>0.551351</td>\n",
       "      <td>0.518919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP3 player</td>\n",
       "      <td>0.598848</td>\n",
       "      <td>0.591298</td>\n",
       "      <td>0.550117</td>\n",
       "      <td>0.628917</td>\n",
       "      <td>0.617716</td>\n",
       "      <td>0.592075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hitachi router</td>\n",
       "      <td>0.615766</td>\n",
       "      <td>0.610039</td>\n",
       "      <td>0.590734</td>\n",
       "      <td>0.644181</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nikon coolpix</td>\n",
       "      <td>0.574220</td>\n",
       "      <td>0.568376</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.591316</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diaper Champ</td>\n",
       "      <td>0.625641</td>\n",
       "      <td>0.619217</td>\n",
       "      <td>0.544484</td>\n",
       "      <td>0.655113</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.648936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nokia 6600</td>\n",
       "      <td>0.640099</td>\n",
       "      <td>0.583133</td>\n",
       "      <td>0.503614</td>\n",
       "      <td>0.613690</td>\n",
       "      <td>0.575540</td>\n",
       "      <td>0.503597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iPod</td>\n",
       "      <td>0.615638</td>\n",
       "      <td>0.544081</td>\n",
       "      <td>0.541562</td>\n",
       "      <td>0.676334</td>\n",
       "      <td>0.563910</td>\n",
       "      <td>0.616541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linksys Router</td>\n",
       "      <td>0.631895</td>\n",
       "      <td>0.598592</td>\n",
       "      <td>0.598592</td>\n",
       "      <td>0.689562</td>\n",
       "      <td>0.678322</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Norton</td>\n",
       "      <td>0.607793</td>\n",
       "      <td>0.603509</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.646999</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.494737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.614361</td>\n",
       "      <td>0.592841</td>\n",
       "      <td>0.536739</td>\n",
       "      <td>0.633102</td>\n",
       "      <td>0.598681</td>\n",
       "      <td>0.567335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product  precision_train  recall_train  accuracy_train  \\\n",
       "0      DVD player         0.619350      0.617329        0.536101   \n",
       "1      MP3 player         0.598848      0.591298        0.550117   \n",
       "2  Hitachi router         0.615766      0.610039        0.590734   \n",
       "3   Nikon coolpix         0.574220      0.568376        0.512821   \n",
       "4    Diaper Champ         0.625641      0.619217        0.544484   \n",
       "5      Nokia 6600         0.640099      0.583133        0.503614   \n",
       "6            iPod         0.615638      0.544081        0.541562   \n",
       "7  Linksys Router         0.631895      0.598592        0.598592   \n",
       "8          Norton         0.607793      0.603509        0.452632   \n",
       "9         Average         0.614361      0.592841        0.536739   \n",
       "\n",
       "   precision_test  recall_test  accuracy_test  \n",
       "0        0.551806     0.551351       0.518919  \n",
       "1        0.628917     0.617716       0.592075  \n",
       "2        0.644181     0.609195       0.551724  \n",
       "3        0.591316     0.564103       0.487179  \n",
       "4        0.655113     0.659574       0.648936  \n",
       "5        0.613690     0.575540       0.503597  \n",
       "6        0.676334     0.563910       0.616541  \n",
       "7        0.689562     0.678322       0.692308  \n",
       "8        0.646999     0.568421       0.494737  \n",
       "9        0.633102     0.598681       0.567335  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_sentiment_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af2fab",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we have:\n",
    "    <li> Devloped a comprehensive NLP pipeline to analyse multiple products</li>\n",
    "    <li> Applied this pipeline to 9 products and examined the performance metrics</li>   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5afeee",
   "metadata": {},
   "source": [
    "### 6. Machine learning method\n",
    "So far our algorithm has operated completely unsupervised!\n",
    "\n",
    "In this section we will trial a machine learning method for predicting sentiment orientation.\n",
    "\n",
    "Specifically, we will transform our sentiment bearing sentences into tf-idf weighted word vectors and apply a Support Vector Classifier (SVC) to predict orientation.\n",
    "\n",
    "We will build our predictions using only the sentences that we have flagged as being sentiment bearing, using our earlier unsupervised method. When creating predictions, sentences that we have flagged as non-sentiment bearing will be given an orientation of 0 for neutral. This will enable us to compare fairly with the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1efaacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_models(x_train, x_test, docs_containing_features_train, docs_containing_features_test,\n",
    "                     y_train_sentiment, y_test_sentiment):\n",
    "    \"\"\"\n",
    "    Train SVM models and return predictions\n",
    "    \"\"\"\n",
    "    # Only train on sentences that we think are sentiment bearing\n",
    "    x_train_list = []\n",
    "    y_train_list = []\n",
    "    for k in docs_containing_features_train.keys(): \n",
    "        x_train_list.append(x_train[k])\n",
    "        y_train_list.append(int(y_train_sentiment['orientation'].loc[k]))\n",
    "\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "    for k in docs_containing_features_test.keys(): \n",
    "        x_test_list.append(x_test[k])\n",
    "        y_test_list.append(int(y_test_sentiment['orientation'].loc[k]))    \n",
    "\n",
    "    # Create tf-idf vectors and train models\n",
    "    vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1, 2))\n",
    "    vectorizer.fit(x_train_list)\n",
    "    vectorizer_vocab = vectorizer.get_feature_names()\n",
    "\n",
    "    x_train_vec = vectorizer.transform(x_train_list).toarray()\n",
    "    x_test_vec = vectorizer.transform(x_test_list).toarray()\n",
    "\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(x_train_vec, y_train_list)\n",
    "\n",
    "    train_preds = clf.predict(x_train_vec)\n",
    "    test_preds = clf.predict(x_test_vec)\n",
    "    \n",
    "    # Reconstruct entire datasets\n",
    "    train_preds_dict = {}\n",
    "    c = 0\n",
    "    for k in x_train.keys(): \n",
    "        if k in docs_containing_features_train.keys():\n",
    "            train_preds_dict[k] = train_preds[c]\n",
    "            c += 1\n",
    "        else:\n",
    "            train_preds_dict[k] = 0\n",
    "            \n",
    "    test_preds_dict = {}\n",
    "    c = 0\n",
    "    for k in x_test.keys(): \n",
    "        if k in docs_containing_features_test.keys():\n",
    "            test_preds_dict[k] = test_preds[c]\n",
    "            c += 1\n",
    "        else:\n",
    "            test_preds_dict[k] = 0\n",
    "            \n",
    "    y_train_sentiment_ml_pred = [v for v in train_preds_dict.values()]\n",
    "    y_test_sentiment_ml_pred = [v for v in test_preds_dict.values()]\n",
    "    \n",
    "    return y_train_sentiment_ml_pred, y_test_sentiment_ml_pred\n",
    "\n",
    "def create_mean_perf_ml(perf_df_all):\n",
    "    \"\"\"\n",
    "    Calculate mean metrics to add as an average row\n",
    "    \"\"\"\n",
    "    mean_dict = {}\n",
    "    mean_perf = perf_df_all.mean(numeric_only=True, axis=0)\n",
    "    mean_dict['product'] = 'Average'\n",
    "    mean_dict['accuracy_train'] = mean_perf['accuracy_train']\n",
    "    mean_dict['accuracy_test'] = mean_perf['accuracy_test']\n",
    "    return mean_dict\n",
    "\n",
    "def run_pipeline_single_product_ml(file, \n",
    "                                    product=\"\",\n",
    "                                    test_percent=0.25, \n",
    "                                    remove_stopwords=False, \n",
    "                                    min_token_length=1,\n",
    "                                    min_support=3,\n",
    "                                    min_percent=0.01, \n",
    "                                    max_feature_distance=5,\n",
    "                                    max_features_review=5,\n",
    "                                    random_seed=42,\n",
    "                                    print_review=True,\n",
    "                                    verbose=False):\n",
    "    \"\"\"\n",
    "    Run the whole NLP pipeline for a single product, using an SVM to predict orientation\n",
    "    \"\"\"\n",
    "    data = read_in(single_file=file)\n",
    "    labels, reviews, other, data_clean = create_dicts(data)\n",
    "    \n",
    "    # Data preprocessing\n",
    "    reviews_clean = clean_text(reviews, remove_stopwords=remove_stopwords, min_token_length=min_token_length)\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = create_train_test_sets(reviews_clean, labels, test_percent, \n",
    "                                                              random_seed=random_seed, verbose=verbose)\n",
    "    \n",
    "    # Extract relevant information\n",
    "    features_dict = get_features(x_train, verbose=verbose)\n",
    "    \n",
    "    features = feature_pruning(x_train, features_dict, min_support=min_support, min_percent=min_percent)\n",
    "    \n",
    "    docs_containing_features_train = find_docs_with_features(x_train, features)\n",
    "    docs_containing_features_test = find_docs_with_features(x_test, features)\n",
    "    opword_dict_train = identify_and_allocate_opinion_words(x_train, docs_containing_features_train, \n",
    "                                                            max_feature_distance=max_feature_distance,\n",
    "                                                            verbose=verbose) \n",
    "    opword_dict_test = identify_and_allocate_opinion_words(x_test, docs_containing_features_test, \n",
    "                                                           max_feature_distance=max_feature_distance,\n",
    "                                                           verbose=verbose) \n",
    "        \n",
    "    polarity_dict_train = calculate_polarity(opword_dict_train)\n",
    "    polarity_dict_test = calculate_polarity(opword_dict_test)\n",
    "    \n",
    "    if print_review:\n",
    "        create_summary_review(product + ' Train', polarity_dict_train, max_features=max_features_review)\n",
    "        create_summary_review(product + ' Test', polarity_dict_test, max_features=max_features_review)\n",
    "        \n",
    "\n",
    "    # Evaluation - Sentiment\n",
    "    y_train_sentiment = create_sentiment_target_df_from_labels(y_train)\n",
    "    y_test_sentiment = create_sentiment_target_df_from_labels(y_test)\n",
    "    \n",
    "    y_train_sentiment_pred, y_test_sentiment_pred = train_svm_models(x_train, x_test, \n",
    "                                                                     docs_containing_features_train, \n",
    "                                                                     docs_containing_features_test, \n",
    "                                                                     y_train_sentiment, \n",
    "                                                                     y_test_sentiment)\n",
    "    \n",
    "    # Calculate performance\n",
    "    acc_train = accuracy_score(y_train_sentiment['orientation'].to_list(), y_train_sentiment_pred)\n",
    "    acc_test = accuracy_score(y_test_sentiment['orientation'].to_list(), y_test_sentiment_pred)\n",
    "    \n",
    "    perf_sentiment = pd.DataFrame({'product':product, 'accuracy_train':acc_train , 'accuracy_test':acc_test},\n",
    "                                  index=[0])\n",
    " \n",
    "    return perf_sentiment\n",
    "\n",
    "\n",
    "def run_pipeline_multiple_products_ml(file_list, \n",
    "                                   product_list,\n",
    "                                   test_percent=0.25, \n",
    "                                   remove_stopwords=False, \n",
    "                                   min_token_length=1,\n",
    "                                   min_support=3,\n",
    "                                   min_percent=0.01, \n",
    "                                   max_feature_distance=5,\n",
    "                                   max_features_review=5,\n",
    "                                   random_seed=42,\n",
    "                                   print_review=False,\n",
    "                                   verbose=False):\n",
    "    \"\"\"\n",
    "    Run the NLP pipeline for multiple products\n",
    "    \"\"\"\n",
    "    if len(file_list) != len(product_list):\n",
    "        raise ValueError(\"The number of files and product names must match\")\n",
    "        \n",
    "    perf_sentiment_all = pd.DataFrame()\n",
    "    \n",
    "    for i, file in enumerate(file_list):\n",
    "        print(f'Running ML pipeline for {product_list[i]}')\n",
    "        perf_sentiment = run_pipeline_single_product_ml(file, \n",
    "                                                        product=product_list[i],\n",
    "                                                        test_percent=test_percent, \n",
    "                                                        remove_stopwords=remove_stopwords, \n",
    "                                                        min_token_length=min_token_length,\n",
    "                                                        min_support=min_support,\n",
    "                                                        min_percent=min_percent, \n",
    "                                                        max_feature_distance=max_feature_distance,\n",
    "                                                        max_features_review=max_features_review,\n",
    "                                                        random_seed=random_seed,\n",
    "                                                        print_review=print_review,\n",
    "                                                        verbose=verbose)\n",
    "        # Append the dataframe\n",
    "        perf_sentiment_all = perf_sentiment_all.append(perf_sentiment)\n",
    "        \n",
    "    \n",
    "    # Add averages\n",
    "    perf_sentiment_all = perf_sentiment_all.append(create_mean_perf_ml(perf_sentiment_all), \n",
    "                                                   ignore_index=True)\n",
    "    return perf_sentiment_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0733a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ML pipeline for DVD player\n",
      "Running ML pipeline for MP3 player\n",
      "Running ML pipeline for Hitachi router\n",
      "Running ML pipeline for Nikon coolpix\n",
      "Running ML pipeline for Diaper Champ\n",
      "Running ML pipeline for Nokia 6600\n",
      "Running ML pipeline for iPod\n",
      "Running ML pipeline for Linksys Router\n",
      "Running ML pipeline for Norton\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_list = ['data/Customer_review_data/Apex AD2600 Progressive-scan DVD player.txt',\n",
    "             'data/Customer_review_data/Creative Labs Nomad Jukebox Zen Xtra 40GB.txt',\n",
    "             'data/Customer_review_data/Nikon coolpix 4300.txt',\n",
    "             'data/Reviews-9-products/Hitachi router.txt',\n",
    "             'data/Reviews-9-products/Diaper Champ.txt',\n",
    "             'data/Reviews-9-products/Nokia 6600.txt',\n",
    "             'data/Reviews-9-products/ipod.txt',\n",
    "             'data/Reviews-9-products/Linksys Router.txt',\n",
    "             'data/Reviews-9-products/norton.txt']\n",
    "\n",
    "product_list = ['DVD player',\n",
    "                'MP3 player',\n",
    "                'Hitachi router',\n",
    "                'Nikon coolpix',\n",
    "                'Diaper Champ',\n",
    "                'Nokia 6600',\n",
    "                'iPod',\n",
    "                'Linksys Router',\n",
    "                'Norton']\n",
    "\n",
    "perf_sentiment_all_ml = run_pipeline_multiple_products_ml(file_list, product_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5faaa0f",
   "metadata": {},
   "source": [
    "After implementing our ML algorithm, we find test set accuracy increases to 0.63 from 0.57 using our original method. This equates to an increase in accuracy of 10.5%! Although still a long way from human level performance, this is a considerable improvement.\n",
    "\n",
    "Further improvements could be made through further hyperparameter tuning to the vectorisation settings and the SVC algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03b70fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DVD player</td>\n",
       "      <td>0.972924</td>\n",
       "      <td>0.605405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MP3 player</td>\n",
       "      <td>0.934732</td>\n",
       "      <td>0.668998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hitachi router</td>\n",
       "      <td>0.926641</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nikon coolpix</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diaper Champ</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nokia 6600</td>\n",
       "      <td>0.898795</td>\n",
       "      <td>0.575540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iPod</td>\n",
       "      <td>0.962217</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linksys Router</td>\n",
       "      <td>0.941315</td>\n",
       "      <td>0.685315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Norton</td>\n",
       "      <td>0.943860</td>\n",
       "      <td>0.515789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.952437</td>\n",
       "      <td>0.633816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product  accuracy_train  accuracy_test\n",
       "0      DVD player        0.972924       0.605405\n",
       "1      MP3 player        0.934732       0.668998\n",
       "2  Hitachi router        0.926641       0.689655\n",
       "3   Nikon coolpix        0.991453       0.564103\n",
       "4    Diaper Champ        1.000000       0.670213\n",
       "5      Nokia 6600        0.898795       0.575540\n",
       "6            iPod        0.962217       0.729323\n",
       "7  Linksys Router        0.941315       0.685315\n",
       "8          Norton        0.943860       0.515789\n",
       "9         Average        0.952437       0.633816"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_sentiment_all_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b5728",
   "metadata": {},
   "source": [
    "<font color='blue' weight='bold'>\n",
    "    <b>Summary</b><br>\n",
    "    In this section we have:\n",
    "    <li> Modified our pipeline to use tf-idf word vectors and a SVC to predict sentiment orientation </li>\n",
    "    <li> Observed an increase in test set accuracy of 10.5% from using these methods </li>   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6716d5",
   "metadata": {},
   "source": [
    "### 7. Conclusions\n",
    "\n",
    "In this assignment we have carried out opinion mining to extract important product features and understand the sentiment towards these features and for each sentence in a review.\n",
    "\n",
    "To meet this end we have built a comprehensive NLP pipeline that reads in data, cleans it, identifies relevant features, opinion words and sentence level sentiment. Our pipeline is capable of producing review summaries to understand the key features and their sentiment orientations. We have analysed the performance of our algorithm through performance metrics of precision, recall and accuracy.\n",
    "\n",
    "As an extension to our algorithm, we have trialled a machine learning model for predicting sentence orientation. We find that the use of tf-idf vectors and SVC increase average orientation accuracy by 10.5%, from 0.57 to 0.63.\n",
    "\n",
    "Overall, the results of our algorithm are far from the performance we would expect of a human, however performance could be greatly improved through invstigation of other methods such as dependency parsing and utilisation of state of the art techiques such as transformer models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79322a1a",
   "metadata": {},
   "source": [
    "### 8. References\n",
    "- Hu, M. and Liu, B., 2004. Mining Opinion Features in Customer Reviews. Proceedings of AAAI.\n",
    "- Hu, M. and Liu, B., 2004. Mining and summarizing customer reviews. [Online], KDD-2004 - Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp.168–177. Available from:                 https://doi.org/10.1145/1014052.1014073.\n",
    "- Wu, Y., Zhang, Q., Huang, X. and Wu, L., 2009. Phrase dependency parsing for opinion mining. Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, USA. EMNLP ’09. USA: Association for Computational Linguistics, pp.1533–1541.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
